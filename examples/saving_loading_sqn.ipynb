{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import policy, RL agent and Gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install \"gymnasium[box2d]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from deeprl import DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use the [Lunar Lander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) environment from OpenAI Gymnasium. This environment features a discrete action space and a continuous state space. To solve it, we will leverage the `deeprl` library, which provides an implementation of the Deep Q-Network (DQN) algorithm.\n",
    "\n",
    "Landing outside the landing pad is possible but with a penalty. Fuel is infinite, so an agent can learn to fly and then land on its first attempt. Four discrete actions are available: do nothing, fire left orientation engine, fire main engine, fire right orientation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'LunarLander-v3'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    \"LunarLander-v3\",\n",
    "    verbose=1,\n",
    "    exploration_final_eps=0.1,\n",
    "    target_update_interval=250,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the `MlpPolicy` (Multi-Layer Perceptron policy) for this task because the input is a feature vector of length 8 rather than an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a function to evaluate the agent's performance before and after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeprl.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lest's evaluate the agent's performance before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgalindo/max/projects/DeepRL/deeprl/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward=-554.75 +/- 183.47134486961076\n"
     ]
    }
   ],
   "source": [
    "# Separate env for evaluation\n",
    "eval_env = gym.make(\"LunarLander-v3\")\n",
    "\n",
    "# Random Agent, before training\n",
    "mean_reward, std_reward = evaluate_policy(\n",
    "    model,\n",
    "    eval_env,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean reward is $-554.75 \\pm 183.471$ wich is very low. The agent is not able to land the lunar lander. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the agent and save it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84       |\n",
      "|    ep_rew_mean      | -210     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1357     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 336      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 58       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.4     |\n",
      "|    ep_rew_mean      | -167     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1541     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 643      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.91     |\n",
      "|    n_updates        | 135      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.8     |\n",
      "|    ep_rew_mean      | -178     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1649     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 970      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.89     |\n",
      "|    n_updates        | 217      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.7     |\n",
      "|    ep_rew_mean      | -181     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1691     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1451     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.732    |\n",
      "|    n_updates        | 337      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.2     |\n",
      "|    ep_rew_mean      | -199     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1688     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1904     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.872    |\n",
      "|    n_updates        | 450      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.4     |\n",
      "|    ep_rew_mean      | -193     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1691     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2265     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 541      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.8     |\n",
      "|    ep_rew_mean      | -212     |\n",
      "|    exploration_rate | 0.764    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1684     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2626     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 631      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.5     |\n",
      "|    ep_rew_mean      | -208     |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1671     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3088     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 746      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | -215     |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1646     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3699     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1615     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4491     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 1097     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | -210     |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1589     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 5087     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.34     |\n",
      "|    n_updates        | 1246     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | -210     |\n",
      "|    exploration_rate | 0.481    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1561     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 5765     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.728    |\n",
      "|    n_updates        | 1416     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | -206     |\n",
      "|    exploration_rate | 0.358    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1418     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 7128     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.607    |\n",
      "|    n_updates        | 1756     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | -198     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 1033     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 11128    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 2756     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -190     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 924      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 15128    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 3756     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 287      |\n",
      "|    ep_rew_mean      | -185     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 18337    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 4559     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 303      |\n",
      "|    ep_rew_mean      | -190     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 878      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 20626    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.813    |\n",
      "|    n_updates        | 5131     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -195     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 22096    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.755    |\n",
      "|    n_updates        | 5498     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 300      |\n",
      "|    ep_rew_mean      | -202     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 888      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 22800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.884    |\n",
      "|    n_updates        | 5674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 293      |\n",
      "|    ep_rew_mean      | -210     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 23405    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.4      |\n",
      "|    n_updates        | 5826     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 306      |\n",
      "|    ep_rew_mean      | -213     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 25716    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 6403     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 311      |\n",
      "|    ep_rew_mean      | -218     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 27338    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 6809     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 313      |\n",
      "|    ep_rew_mean      | -222     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 28837    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.77     |\n",
      "|    n_updates        | 7184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 307      |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 886      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 29506    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 7351     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -226     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 30240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 7534     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 316      |\n",
      "|    ep_rew_mean      | -222     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 887      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 31980    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.93     |\n",
      "|    n_updates        | 7969     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 346      |\n",
      "|    ep_rew_mean      | -222     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 35272    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.998    |\n",
      "|    n_updates        | 8792     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 383      |\n",
      "|    ep_rew_mean      | -217     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 855      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 39272    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.894    |\n",
      "|    n_updates        | 9792     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 410      |\n",
      "|    ep_rew_mean      | -215     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 42452    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.883    |\n",
      "|    n_updates        | 10587    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 432      |\n",
      "|    ep_rew_mean      | -211     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 858      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 45099    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 11249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 458      |\n",
      "|    ep_rew_mean      | -207     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 856      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 48101    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.777    |\n",
      "|    n_updates        | 12000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 476      |\n",
      "|    ep_rew_mean      | -196     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 859      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 50188    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.607    |\n",
      "|    n_updates        | 12521    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 495      |\n",
      "|    ep_rew_mean      | -193     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 862      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 52619    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.581    |\n",
      "|    n_updates        | 13129    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 505      |\n",
      "|    ep_rew_mean      | -187     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 54247    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.948    |\n",
      "|    n_updates        | 13536    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 511      |\n",
      "|    ep_rew_mean      | -179     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 55572    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 13867    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 524      |\n",
      "|    ep_rew_mean      | -181     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 878      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 57453    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.769    |\n",
      "|    n_updates        | 14338    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 537      |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 59416    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.739    |\n",
      "|    n_updates        | 14828    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 536      |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 60702    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.835    |\n",
      "|    n_updates        | 15150    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 512      |\n",
      "|    ep_rew_mean      | -173     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 887      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 62369    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.728    |\n",
      "|    n_updates        | 15567    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 486      |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 891      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 63711    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.68     |\n",
      "|    n_updates        | 15902    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 465      |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 64876    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 16193    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 459      |\n",
      "|    ep_rew_mean      | -168     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 900      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 66554    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 16613    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 458      |\n",
      "|    ep_rew_mean      | -162     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 67925    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.845    |\n",
      "|    n_updates        | 16956    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 472      |\n",
      "|    ep_rew_mean      | -155     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 906      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 69950    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.68     |\n",
      "|    n_updates        | 17462    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 475      |\n",
      "|    ep_rew_mean      | -146     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 909      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 70864    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 17690    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 467      |\n",
      "|    ep_rew_mean      | -141     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 913      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 72445    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.953    |\n",
      "|    n_updates        | 18086    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 463      |\n",
      "|    ep_rew_mean      | -134     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 916      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 73656    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.802    |\n",
      "|    n_updates        | 18388    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 460      |\n",
      "|    ep_rew_mean      | -128     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 920      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 74812    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.711    |\n",
      "|    n_updates        | 18677    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 466      |\n",
      "|    ep_rew_mean      | -121     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 922      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 76102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.713    |\n",
      "|    n_updates        | 19000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 475      |\n",
      "|    ep_rew_mean      | -117     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 77751    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.716    |\n",
      "|    n_updates        | 19412    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 470      |\n",
      "|    ep_rew_mean      | -118     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 929      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 78986    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.77     |\n",
      "|    n_updates        | 19721    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 451      |\n",
      "|    ep_rew_mean      | -119     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 930      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 80404    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.795    |\n",
      "|    n_updates        | 20075    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 432      |\n",
      "|    ep_rew_mean      | -120     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 932      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 82462    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.847    |\n",
      "|    n_updates        | 20590    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 411      |\n",
      "|    ep_rew_mean      | -121     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 936      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 83511    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.15     |\n",
      "|    n_updates        | 20852    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 395      |\n",
      "|    ep_rew_mean      | -122     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 939      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 84578    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.287    |\n",
      "|    n_updates        | 21119    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 377      |\n",
      "|    ep_rew_mean      | -126     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 942      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 85766    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.704    |\n",
      "|    n_updates        | 21416    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 381      |\n",
      "|    ep_rew_mean      | -129     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 942      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 88247    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 22036    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 373      |\n",
      "|    ep_rew_mean      | -132     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 944      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 89957    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.913    |\n",
      "|    n_updates        | 22464    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 369      |\n",
      "|    ep_rew_mean      | -135     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 947      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 91170    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.696    |\n",
      "|    n_updates        | 22767    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 366      |\n",
      "|    ep_rew_mean      | -137     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 92198    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.565    |\n",
      "|    n_updates        | 23024    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 359      |\n",
      "|    ep_rew_mean      | -139     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 93353    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.64     |\n",
      "|    n_updates        | 23313    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 353      |\n",
      "|    ep_rew_mean      | -144     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 94746    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.431    |\n",
      "|    n_updates        | 23661    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 363      |\n",
      "|    ep_rew_mean      | -148     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 97030    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.666    |\n",
      "|    n_updates        | 24232    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 357      |\n",
      "|    ep_rew_mean      | -150     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 98064    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.423    |\n",
      "|    n_updates        | 24490    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 357      |\n",
      "|    ep_rew_mean      | -152     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 99456    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.44     |\n",
      "|    n_updates        | 24838    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "model.learn(total_timesteps=int(1e5))\n",
    "# Save the agent\n",
    "model.save(\"dqn_lunar\")\n",
    "del model  # delete trained model to demonstrate loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After train the model, we save and then delete the model to demostrate how to load the model and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(\"dqn_lunar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward=-182.64 +/- 56.59685950385565\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained agent\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the mean reward is better than before. The agent is able to do a better job at landing the lunar lander."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "obs, info = env.reset()\n",
    "while True:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
